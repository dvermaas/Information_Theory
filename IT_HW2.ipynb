{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "name": "IT_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIMisj3ap4OO"
      },
      "source": [
        "__Name:__ DanÃ«l Vermaas<br>\n",
        "__UvAID:__: 12208698"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-JvYXnQpsYv"
      },
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from collections import defaultdict"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa-xcEljpsYy"
      },
      "source": [
        "In this homework, you will implement the Huffmann compression algorithm discussed in class.\n",
        "\n",
        "We are going compress Shakespear's Hamlet, so let us download the text (courtesy of Project Gutenberg). Borges' [The Library of Babel](https://en.wikipedia.org/wiki/The_Library_of_Babel) would be even more fitting to compress. Unfortunately it is not yet in the public domain..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7vP-PQMpsYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa0eb8c-8854-4b35-fc7b-797808d380f1"
      },
      "source": [
        "URL = \"https://github.com/amsqi/iit21-homework/raw/main/material/hamlet.txt\"\n",
        "hamlet = requests.get(URL).content.decode(\"ascii\", errors=\"ignore\")\n",
        "hamlet = hamlet\n",
        "len(hamlet)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179096"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW6sM7pLpsY0"
      },
      "source": [
        "Thus we have around 180 KB to compress!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xaSik6QpsY0"
      },
      "source": [
        "# 1. Huffman Compression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aUaj-QfpsY1"
      },
      "source": [
        "Throughout this exercise, we use the following conventions:\n",
        "- **probability distributions** are represented by dictionaries that map symbols to probabilities\n",
        "- **bitstrings** are represented by Python lists or tuples that contain 0s and 1s (for simplicity)\n",
        "- **codes** are represented by dictionaries that map symbols to bitstrings\n",
        "\n",
        "The following function can be used to compute the average length of a code $C$ under a probability distribution $P$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwJusAAXpsY1"
      },
      "source": [
        "def L(C, P):\n",
        "    return sum(P[x] * len(C[x]) for x in P if P[x] > 0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrVTcjbopsY3"
      },
      "source": [
        "And the following function tests if a given code is a prefix code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h69Yi1LpsY3"
      },
      "source": [
        "def is_prefix_code(C):\n",
        "    # sort codewords by length\n",
        "    codewords = sorted(C.values(), key=len)\n",
        "\n",
        "    # check if any codeword is prefix of any other\n",
        "    for i, first in enumerate(codewords):\n",
        "        l = len(first)\n",
        "        for second in codewords[i + 1 :]:\n",
        "            if second[:l] == first:\n",
        "                return False\n",
        "    return True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVaVxNBYpsY4"
      },
      "source": [
        "Here is a simple example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qgpvj1epsY5"
      },
      "source": [
        "P = {\"X\": 0.5, \"O\": 0.3, \"L\": 0.2}\n",
        "\n",
        "C = {\"X\": [0], \"O\": [1, 0], \"L\": [1, 1]}\n",
        "assert is_prefix_code(C) and L(C, P) == 1.5\n",
        "\n",
        "C = {\"X\": [0], \"O\": [0, 0], \"L\": [0, 0, 0]}\n",
        "assert not is_prefix_code(C) and np.round(L(C, P), 1) == 1.7"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w1iHdUwpsY5"
      },
      "source": [
        "**Your first task is to implement Huffmann's algorithm for creating the optimal prefix code for a given probability distribution.**\n",
        "\n",
        "Your function should take as input a probability distribution $P$ and return as output a code $C$ (in the format described above)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJBGjlTeCCZg",
        "outputId": "4c204f1f-3d3d-4d4b-c4b7-ba08bf2d4e37"
      },
      "source": [
        "def huffman_code(P):\n",
        "  P_list = [([k],v) for k, v in sorted(P.items(), key=lambda item: item[1])]\n",
        "  out = defaultdict(list)\n",
        "  # Contine until we have one element left\n",
        "  while len(P_list) >= 2:\n",
        "    p_total = 0\n",
        "    new_key = []\n",
        "    # grab 2 elements and combine them\n",
        "    for i in reversed(range(2)):\n",
        "      letter_list, p = P_list.pop(0)\n",
        "      p_total += p\n",
        "      for letter in letter_list:\n",
        "        new_key.append(letter)\n",
        "        out[letter].insert(0, i)\n",
        "    # add the combination back into tree options\n",
        "    P_list.insert(0, (new_key, p_total))\n",
        "    P_list.sort(key=lambda x:x[1])\n",
        "  # returning as normal dict in case of autograder\n",
        "  return dict(out)\n",
        "\n",
        "huffman_code({\"X\": 0.5, \"O\": 0.3, \"L\": 0.2})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'L': [1, 1], 'O': [1, 0], 'X': [0]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2o2r90iFGKh"
      },
      "source": [
        "__Here we use the created functions to answer homework exercise 1__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eWPruLbDxZY",
        "outputId": "8fac3e86-92c6-49d8-ac6f-629f37547d4b"
      },
      "source": [
        "# 1a\n",
        "P = {\"A\" : 0.05, \"B\" : 0.05, \"C\" : 0.07, \"D\" : 0.13, \"E\" : 0.2, \"F\" : 0.2, \"G\" : 0.3}\n",
        "def shannon_entropy(P):\n",
        "  return sum([p_x * np.log2(1/p_x) for p_x in P.values()])\n",
        "\n",
        "print(\"Shannon entropy = \", shannon_entropy(P))\n",
        "\n",
        "# 1b\n",
        "C = huffman_code(P)\n",
        "print(\"Code:\", C)\n",
        "print(\"Avg length:\", L(C, P))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shannon entropy =  2.533252955746114\n",
            "Code: {'A': [0, 0, 0, 0, 1], 'B': [0, 0, 0, 0, 0], 'C': [0, 0, 0, 1], 'D': [0, 0, 1], 'E': [1, 1], 'F': [1, 0], 'G': [0, 1]}\n",
            "Avg length: 2.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EejXssdTpsY6"
      },
      "source": [
        "Here are some test cases that you can run to make sure that your code works:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE-pZpM9psY6"
      },
      "source": [
        "# the probability distribution from class\n",
        "P = {\"A\": 0.25, \"B\": 0.25, \"C\": 0.2, \"D\": 0.15, \"E\": 0.15}\n",
        "C = huffman_code(P)\n",
        "assert is_prefix_code(C)\n",
        "assert L(C, P) == 2.3\n",
        "\n",
        "# uniform probability distribution over a byte (8 bits)\n",
        "P = {k: 1 / 256 for k in range(256)}\n",
        "C = huffman_code(P)\n",
        "assert is_prefix_code(C)\n",
        "assert L(C, P) == 8\n",
        "\n",
        "# letter distribution of the English language (from MacKay's book)\n",
        "P = {\n",
        "    \"a\": 0.0575,\n",
        "    \"b\": 0.0128,\n",
        "    \"c\": 0.0263,\n",
        "    \"d\": 0.0285,\n",
        "    \"e\": 0.0913,\n",
        "    \"f\": 0.0173,\n",
        "    \"g\": 0.0133,\n",
        "    \"h\": 0.0313,\n",
        "    \"i\": 0.0599,\n",
        "    \"j\": 0.0006,\n",
        "    \"k\": 0.0084,\n",
        "    \"l\": 0.0335,\n",
        "    \"m\": 0.0235,\n",
        "    \"n\": 0.0596,\n",
        "    \"o\": 0.0689,\n",
        "    \"p\": 0.0192,\n",
        "    \"q\": 0.0008,\n",
        "    \"r\": 0.0508,\n",
        "    \"s\": 0.0567,\n",
        "    \"t\": 0.0706,\n",
        "    \"u\": 0.0334,\n",
        "    \"v\": 0.0069,\n",
        "    \"w\": 0.0119,\n",
        "    \"x\": 0.0073,\n",
        "    \"y\": 0.0164,\n",
        "    \"z\": 0.0007,\n",
        "    \" \": 0.1928,\n",
        "}\n",
        "C = huffman_code(P)\n",
        "assert is_prefix_code(C)\n",
        "assert np.round(L(C, P), 2) == 4.15"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZTadKl5psY6"
      },
      "source": [
        "When compressing strings in practice, what probability distribution $P$ should we use to construct the Huffman code? A simple guess is the empirical probability distribution of the string. It is given by\n",
        "$$P(x) = \\frac {N_n} N,$$\n",
        "where $N$ is the length of the string and $N_x$ the number of times that symbol $x$ appears in it.\n",
        "\n",
        "**Write a function that takes as input a string or list of symbols and returns as output its empirical probability distribution.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t622p9sApsY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682d83e3-d3a5-4cde-afa3-81b1b6c0897a"
      },
      "source": [
        "def empirical(s):\n",
        "    tf = defaultdict(int)\n",
        "    for letter in s:\n",
        "      tf[letter] += 1\n",
        "    return {k: v / len(s) for k, v in tf.items()}\n",
        "\n",
        "empirical(\"ABBBBA\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A': 0.3333333333333333, 'B': 0.6666666666666666}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1ZRhsYApsY7"
      },
      "source": [
        "assert empirical(\"ABBBBA\") == {\"A\": 2 / 6, \"B\": 4 / 6}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h62im5fpsY7"
      },
      "source": [
        "We are now in a good situation to compress an arbitrary unknown string.\n",
        "\n",
        "**Write a function that takes as input a string and as output returns a pair `(C,bs)`, where `C` is a Huffman code for the empirical probability distribution and where `bs` is a bitstring containing the compression of the input.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_pElEGepsY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0049be67-af65-49f3-a845-a90885524dca"
      },
      "source": [
        "def huffman_compress(s):\n",
        "  bitstring= \"\"\n",
        "  distribution = empirical(s)\n",
        "  code = huffman_code(distribution)\n",
        "  code = {key : [str(bit) for bit in bits] for key, bits in code.items()}\n",
        "  for letter in s:\n",
        "    bitcode = \"\"\n",
        "    bitstring += bitcode.join(code[letter])\n",
        "  return code, bitstring\n",
        "\n",
        "huffman_compress(\"ABCCBBBA\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'A': ['1', '1'], 'B': ['0'], 'C': ['1', '0']}, '110101000011')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyZtZ6NEpsY8"
      },
      "source": [
        "For your convenience, we already programmed a decompressor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPmf1yxypsY8"
      },
      "source": [
        "def huffman_decompress(C, bs):\n",
        "    def tree():\n",
        "        return defaultdict(tree)\n",
        "\n",
        "    # build a binary tree for \"fast\" decompression\n",
        "    root = tree()\n",
        "    for x, cw in C.items():\n",
        "        node = root\n",
        "        for b in cw[:-1]:\n",
        "            node = node[b]\n",
        "        node[cw[-1]] = x\n",
        "\n",
        "    # walk tree bit by bit\n",
        "    result = \"\"\n",
        "    node = root\n",
        "    for b in bs:\n",
        "        node = node[b]\n",
        "\n",
        "        # if we are at a leave, emit the corresponding symbol and return to root\n",
        "        if not isinstance(node, dict):\n",
        "            result += node\n",
        "            node = root\n",
        "    return result"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHw5NBeupsY8"
      },
      "source": [
        "Here is a simple test to make sure that your compressor works fine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZYlfD00psY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e22acc-e16c-490e-9bce-dcee6a105ce1"
      },
      "source": [
        "PLAIN_TEXT = \"Welcome to the quantum quest.\"\n",
        "C, bs = huffman_compress(PLAIN_TEXT)\n",
        "assert huffman_decompress(C, bs) == PLAIN_TEXT\n",
        "print(f\"Successfully compressed {len(PLAIN_TEXT)*8} bits into {len(bs)} bits\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully compressed 232 bits into 107 bits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnuGr8DFpsY8"
      },
      "source": [
        "Of course, most savings here come from the fact that we don't use the full range of characters. What compression rate do you achieve when compressing Hamlet? Run the following code to find out:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYkJZkWZpsY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b633e9-49a2-47ab-e71b-c7846a9a0973"
      },
      "source": [
        "# compress hamlet\n",
        "C, compressed = huffman_compress(hamlet)\n",
        "\n",
        "# make sure it decompresses correctly\n",
        "assert huffman_decompress(C, compressed) == hamlet\n",
        "\n",
        "# print compression ratio\n",
        "compressed_bytes = len(compressed) / 8\n",
        "R = compressed_bytes / len(hamlet)\n",
        "print(f\"Compression rate: {R:2.0%}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compression rate: 58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxjJ2fbopsY9"
      },
      "source": [
        "**Bonus challenges for the Huffman problem (completely optional):**\n",
        "\n",
        "1. Download the `enwik8` data set from http://mattmahoney.net/dc/textdata.html. It contains the first 100 MB of a Wikipedia data dump. Optimize your Huffman compressor so that it can compress this data set in a few seconds! Does the decompressor need any optimizing, too?\n",
        "2. In a realistic compressor, you would return the codebook `C` as part of the bitstring `bs`. Implement this and see to which extent this impacts your compression rate."
      ]
    }
  ]
}